{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Case Study [Seoul, South Korea]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Map Area\n",
    "    - Seoul, South Korea (central part)  \n",
    "      \n",
    "    https://mapzen.com/data/metro-extracts/metro/seoul_south-korea/  \n",
    "    \n",
    "    This is my hometown, Seoul, the capital of South Korea. I decided to take a deep look into the open street map dataset and figure out what I can contribute. Originally, The boundary of dataset was wider than current dataset, which was containg mixed area of Seoul and non-Seoul. I tried to reduce the boundary so that it can contain the central part of the Seoul. Consequently, the size of dataset reduced from 337.1MB to 79.5MB.  \n",
    "   \n",
    "    - Changes  \n",
    "\n",
    "    From  \n",
    "        minlat=\"37.019\"   \n",
    "        minlon=\"126.064\"   \n",
    "        maxlat=\"37.98\"   \n",
    "        maxlon=\"127.525\"  \n",
    "  \n",
    "    To  \n",
    "        minlat=\"37.4694085\"   \n",
    "        minlon=\"126.8845367\"   \n",
    "        maxlat=\"37.6115117\"   \n",
    "        maxlon=\"127.1063232\"  \n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Import Data\n",
    "\n",
    "    - Libraries  \n",
    "\n",
    "    Imported libraries(csv, codec, pprint, re, cElementTree, cerberus) needed and defined schema to check validity.\n",
    "    \n",
    "    - Schema  \n",
    "    \n",
    "    If the element top level tag is \"node\": The dictionary returned have the format {\"node\": .., \"node_tags\": ...}. The \"node\" field hold a dictionary of the following top level node attributes: id / user / uid / version / lat / lon / timestamp / changeset and all other attributes are ignored\n",
    "\n",
    "    The \"node_tags\" field should hold a list of dictionaries, one per secondary tag. Secondary tags are\n",
    "    child tags of node which have the tag name/type: \"tag\". Each dictionary should have the following\n",
    "    fields from the secondary tag attributes:\n",
    "    id: the top level node id attribute value\n",
    "    key: the full tag \"k\" attribute value if no colon is present or the characters after the colon if one is.\n",
    "    value: the tag \"v\" attribute value\n",
    "    type: either the characters before the colon in the tag \"k\" value or \"regular\" if a colon is not present.\n",
    "\n",
    "    If the element top level tag is \"way\": the dictionary have the format {\"way\": ..., \"way_tags\": ..., \"way_nodes\": ...}. The \"way\" field hold a dictionary of the following top level way attributes: id / user / uid / version / timestamp / changeset and all other attributes can be ignored\n",
    "\n",
    "    The \"way_tags\" field hold a list of dictionaries, following the exact same rules as for \"node_tags\".\n",
    "\n",
    "    Additionally, the dictionary should have a field \"way_nodes\". \"way_nodes\" hold a list of dictionaries, one for each nd child tag.  Each dictionary should have the fields:\n",
    "    id: the top level element (way) id\n",
    "    node_id: the ref attribute value of the nd tag\n",
    "    position: the index starting at 0 of the nd tag i.e. what order the nd tag appears within the way element\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "import cerberus\n",
    "\n",
    "OSM_PATH = \"central-seoul_south-korea.osm\"\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "SCHEMA = {\n",
    "    'node': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'lat': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'lon': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'node_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'way_nodes': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'node_id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'position': {'required': True, 'type': 'integer', 'coerce': int}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Helper Functions  \n",
    "    \n",
    "     'get_element' function parse osm file with tags named 'node' and 'way'. 'validate_element' check if there are mismatches in fields created and schema. 'UnicodeDictWriter' encode Korean language into unicode and write data on file with unicode so that Korean can be used in csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Keys of tag\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'name': 14278, 'name:en': 11185, 'name:ko': 9346, 'name:ko_rm': 8978, 'amenity': 5697, 'source': 5319, 'ncat': 5200, 'highway': 4418, 'route_ref': 3637, 'railway': 1567, 'tourism': 1082, 'shop': 1066, 'name:ja': 1051, 'addr:street': 642, 'addr:housenumber': 620, 'building': 513, 'place': 406, 'addr:postcode': 401, 'addr:city': 381, 'entrance': 380, 'cuisine': 376, 'public_transport': 293, 'subway': 257, 'barrier': 245, 'historic': 227, 'ref': 211, 'natural': 148, 'website': 147, 'phone': 144, 'opening_hours': 143, 'operator': 142, 'atm': 138, 'level': 133, 'leisure': 115, 'crossing': 107, 'station': 106, 'internet_access': 101, 'direction': 98, 'information': 96, 'wheelchair': 95, 'access': 92, 'junction': 90, 'layer': 78, 'material': 77, 'artwork_type': 75, 'foot': 72, 'board_type': 72, 'religion': 71, 'landuse': 66, 'description:en': 62, 'fixme': 59, 'man_made': 59, 'wikipedia': 58, 'noexit': 57, 'ele': 56, 'note': 54, 'statue': 53, 'name:zh': 52, 'network': 47, 'smoking': 46, 'level:ref': 44, 'old_operator': 44, 'bridge': 42, 'height': 42, 'source:bridge': 41, 'ncat:bridge': 41, 'bridge:name:ko': 41, 'bridge:name:ko_rm': 41, 'bridge:name:en': 41, 'bridge:name': 41, 'office': 40, 'mapillary': 40, 'indoor': 37, 'bicycle': 36, 'name:el': 36, 'parking': 35, 'alt_name:ko': 35, 'backrest': 35, 'addr:housename': 33, 'statue:animal': 32, 'power': 28, 'seats': 27, 'fee': 26, 'description': 25, 'internet_access:fee': 25, 'takeaway': 25, 'leaf_type': 25, 'camera:mount': 24, 'image': 24, 'camera:type': 24, 'payment:bitcoin': 24, 'leaf_cycle': 24, 'surveillance': 24, 'surveillance:type': 24, 'surveillance:zone': 23, 'name:de': 23, 'brand': 23, 'route_ref_1': 23, 'camera:direction': 22, 'denomination': 22, 'alt_name': 20, 'start_date': 20, 'sport': 19, 'memorial': 19, 'tank:type': 17, 'colour': 17, 'aircraft:type': 17, 'platforms': 17, 'aircraft:military': 17, 'aeroway': 16, 'contact:website': 16, 'route_ref_2': 16, 'cannon:type': 15, 'manufacturer': 15, 'is_in': 14, 'capacity': 14, 'building:material': 14, 'species': 13, 'name:fr': 13, 'designation': 13, 'bench': 13, 'genus': 13, 'denotation': 13, 'taxon': 12, 'bus': 12, 'covered': 11, 'historic:period': 11, 'historic:civilization': 11, 'model': 11, 'emergency': 11, 'delivery': 11, 'diet:vegetarian': 10, 'email': 10, 'outdoor_seating': 9, 'room': 8, 'heritage:description': 8, 'diet:vegan': 8, 'country': 8, 'seating': 8, 'language:en': 8, 'heritage': 8, 'shelter': 8, 'created_by': 7, 'disused': 7, 'population': 7, 'id': 7, 'route_ref_3': 7, 'wifi': 7, 'addr:street:ko_rm': 6, 'int_name': 6, 'craft': 6, 'waterway': 6, 'addr:city:en': 6, 'support': 6, 'ref:sha': 5, 'military': 5, 'missile:type': 5, 'horse': 5, 'language:ko': 5, 'name:ru': 5, 'alt_name:en': 5, 'technical_monument': 5, 'traffic_signals:sound': 5, 'button_operated': 5, 'contact:phone': 5, 'addr:city:ko_rm': 5, 'school': 4, 'wikipedia:en': 4, 'food': 4, 'aerialway': 4, 'motorcar': 4, 'name:es': 4, 'map_size': 4, 'toilets:disposal': 4, 'addr:country': 4, 'supervised': 4, 'recycling_type': 4, 'language:kr': 3, 'tower:type': 3, 'motor_vehicle': 3, 'name:it': 3, 'language:others': 3, 'service:bicycle:retail': 3, 'traffic_calming': 3, 'FIXME': 3, 'cash_in': 3, 'language:ch': 3, 'unisex': 3, 'access:note': 3, 'short_name': 3, 'internet_access:type': 3, 'currency:KRW': 3, 'location': 3, 'internet_access:ssid': 3, 'name_1': 3, 'speech_output:kr': 3, 'traffic_signals': 3, 'heritage:operator': 3, 'missile:range': 2, 'fax': 2, 'name:pt': 2, 'club': 2, 'service:bicycle:second_hand': 2, 'male': 2, 'gate': 2, 'addr:place': 2, 'name.source:en': 2, 'restriction': 2, 'motorcycle': 2, 'attraction': 2, 'drive_in': 2, 'inscription:en': 2, 'map_type': 2, 'name:ar': 2, 'naptan:Bearing': 2, 'cha:ref': 2, 'service:bicycle:repair': 2, 'operator:en': 2, 'name:sv': 2, 'toilets:wheelchair': 2, 'park_ride': 2, 'television': 2, 'diplomatic': 2, 'wikidata': 2, 'website:en': 2, 'building:levels': 2, 'theatre': 2, 'name:kn': 2, 'viewpoint:type': 2, 'cocktails': 2, 'website:ko': 2, 'note:en': 2, 'drive_through': 2, 'addr:place:ko_rm': 2, 'surface': 2, 'ship:type': 2, 'milestone_type': 2, 'vehicle:type': 2, 'vending': 2, 'female': 2, 'stars': 2, 'branch': 2, 'maxstay': 2, 'route_ref_4': 2, 'ele_source': 1, 'service:repair': 1, 'lon:exact': 1, 'name:bat-smg': 1, 'opening_hours:note': 1, 'ref:en': 1, 'name:uz': 1, 'name:ur': 1, 'name:uk': 1, 'is_in:continent': 1, 'name:kr': 1, 'name:is': 1, 'capital': 1, 'name:bs': 1, 'name:bn': 1, 'name:bo': 1, 'name:bh': 1, 'name:bjn': 1, 'name:be': 1, 'name:bg': 1, 'name:ba': 1, 'microbrewery': 1, 'name:crh': 1, 'official_name:en': 1, 'indoor_seating': 1, 'name:pl': 1, 'name:cdo': 1, 'official_name:ko_rm': 1, 'name:rue': 1, 'type': 1, 'end_date': 1, 'visibility': 1, 'train': 1, 'source:lat': 1, u'\\uc544\\uc9c0\\ud2b8102': 1, 'name:pnb': 1, 'name:be-tarask': 1, 'name:mr': 1, 'name:my': 1, 'name:ml': 1, 'name:mn': 1, 'name:mk': 1, 'source:ele': 1, 'eng': 1, 'name:fi': 1, 'beauty': 1, 'name:fa': 1, 'name:tr': 1, 'tourism_2': 1, 'tourism_1': 1, 'name:ta': 1, 'name:tg': 1, 'lat:exact': 1, 'source:population': 1, 'kerb': 1, 'name:gag': 1, 'name:az': 1, 'name:gan': 1, 'inscription:note': 1, 'payment:cash': 1, 'name:an': 1, 'name:af': 1, 'official_name:ko': 1, 'name:sl': 1, 'name:sk': 1, 'free': 1, 'name:arz': 1, 'name:et': 1, 'name:sr': 1, 'route': 1, 'shelter_type': 1, 'name:tpi': 1, 'name:source': 1, 'name:ro': 1, 'name:diq': 1, 'construction_date': 1, 'addr:city_1': 1, 'name:hi': 1, 'name:he': 1, 'artist_name': 1, 'capital_ISO3166-1': 1, 'name:hy': 1, 'name:hu': 1, 'name:hr': 1, 'wikipedia:ko': 1, 'target': 1, 'name:szl': 1, 'addr:suburb': 1, 'addr:floor': 1, 'addr:suburb:ko_rm': 1, 'name:roa-tara': 1, 'addr:full': 1, 'name:Ko_kr': 1, 'is_in:iso_3166_2': 1, 'name:ka': 1, 'name:km': 1, 'name:kk': 1, 'name:ku': 1, 'service:bicycle:rental': 1, 'name:ky': 1, 'name:lv': 1, 'name:lt': 1, 'cannon': 1, 'sorting_name': 1, 'name:la': 1, 'name:eo': 1, 'wheelchair:description': 1, 'name:tk': 1, 'name:th': 1, 'payment:credit_cards': 1, 'name:eu': 1, 'name:ckb': 1, 'name:ast': 1, 'fuel:diesel': 1, 'unmaker space': 1, 'contact:email': 1, 'name:sah': 1, 'name:oc': 1, 'name:os': 1, 'agit102': 1, 'toilets:position': 1, 'name:yi': 1, 'name:vi': 1, 'name:vo': 1, 'cafe': 1, 'name:ext': 1, 'collection_times': 1, 'underground': 1, 'website_1': 1, 'floor': 1, 'name:wuu': 1, 'seasonal': 1, 'name:cv': 1, 'name:cs': 1, 'construction_year': 1, 'name:ca': 1, u'\\ub0a8\\ubd80\\ud130\\ubbf8\\ub110\\uc5f0\\uc2b5\\uc2e4agit102': 1, 'internet_access:password_protected': 1, 'name:dsb': 1, 'short_name:en': 1, 'name:nah': 1, 'local_ref': 1, 'wpt_description': 1, 'name:zh-yue': 1, 'memorial:type': 1, 'name:jbo': 1, 'pastry_shop': 1, 'name_2': 1, 'cinema:3D': 1, 'name:zh-min-nan': 1, 'viewpoint:direction': 1, 'name:mhr': 1, 'admin_level': 1, 'name:csb': 1, u'\\uc11c\\ucd08\\ub3d9\\uc5f0\\uc2b5\\uc2e4\\uc544\\uc9c0\\ud2b8102': 1, 'name:zh-classical': 1, 'diaper': 1, 'name:qu': 1, 'source:alt_name': 1, 'dispensing': 1, 'ref:cha': 1, 'name:am': 1, 'display': 1, 'crossing_ref': 1, 'name:fiu-vro': 1, 'official_name': 1, 'fixeme': 1, 'is_in:country': 1, 'old_name:vi': 1, 'alt_name:vi': 1, 'self_service': 1, 'name:nl': 1, 'is_in:country_code': 1, 'source:lon': 1, 'name:gl': 1})\n",
      "Counter({'highway': 35692, 'name': 26698, 'building': 17679, 'name:en': 5376, 'source': 5072, 'name:ko': 3901, 'oneway': 3178, 'addr:housenumber': 3005, 'addr:street': 2813, 'amenity': 2154, 'name:ko_rm': 2062, 'ncat': 1906, 'review': 1898, 'addr:city': 1450, 'service': 1418, 'name:ja': 1324, 'landuse': 1311, 'layer': 1192, 'railway': 862, 'leisure': 833, 'bridge': 830, 'area': 689, 'ref': 599, 'boundary': 574, 'addr:postcode': 547, 'gauge': 546, 'lanes': 522, 'electrified': 491, 'surface': 479, 'tunnel': 473, 'voltage': 472, 'footway': 472, 'frequency': 436, 'access': 405, 'building:levels': 369, 'shop': 340, 'barrier': 310, 'natural': 261, 'sport': 246, 'usage': 233, 'foot': 224, 'maxspeed': 217, 'crossing': 208, 'height': 185, 'historic': 176, 'level': 159, 'tourism': 156, 'source:name': 142, 'fee': 132, 'incline': 132, 'building:part': 129, 'bicycle': 121, 'source:geometry': 121, 'operator': 117, 'cuisine': 115, 'website': 100, 'colour': 90, 'name:zh': 88, 'sac_scale': 83, 'ele': 83, 'building:material': 83, 'office': 82, 'building:color': 82, 'start_date': 79, 'building:architecture': 77, 'historic:period': 77, 'historic:civilization': 77, 'width': 73, 'waterway': 70, 'alt_name:ko': 65, 'tracks': 62, 'history': 62, 'motor_vehicle': 60, 'religion': 60, 'lit': 59, 'network': 52, 'addr:housename': 51, 'railway:preferred_direction': 49, 'wikipedia': 48, 'railway:ballastless': 44, 'int_name': 44, 'cycleway': 44, 'roof:color': 44, 'note': 42, 'phone': 41, 'embankment': 41, 'covered': 39, 'parking': 39, 'roof:material': 37, 'aeroway': 34, 'railway:bidirectional': 33, 'bridge:name': 33, 'not:name': 31, 'step_count': 31, 'railway:track_ref': 30, 'alt_name': 29, 'building:use': 28, 'access:note': 27, 'toll': 25, 'level:ref': 24, 'construction': 24, 'wheelchair': 23, 'alt_name:en': 23, 'operator:ko': 22, 'man_made': 22, 'opening_hours': 22, 'bus': 22, 'segregated': 21, 'conveying': 20, 'smoking': 20, 'handrail': 20, 'water': 19, 'wikidata': 19, 'bridge:name:ko': 18, 'bridge:name:en': 18, 'indoor': 17, 'admin_level': 17, 'military': 16, 'trail_visibility': 16, 'image': 15, 'roof:shape': 15, 'denomination': 14, 'fixme': 13, 'horse': 13, 'description:en': 13, 'tunnel:name': 12, 'tunnel:name:ko_rm': 12, 'material': 12, 'route': 12, 'tunnel:name:en': 12, 'junction': 11, 'wood': 11, 'emergency': 11, 'internet_access': 11, 'heritage': 11, 'created_by': 10, 'wikipedia:en': 10, 'description': 10, 'designation': 10, 'place': 10, 'country': 10, 'craft': 10, 'conveying:backward': 10, 'power': 10, 'conveying:forward': 10, 'tunnel:name:ko': 10, 'heritage:description': 9, 'cutting': 8, 'public_transport': 8, 'turn:lanes:forward': 7, 'is_in': 7, 'source:highway': 7, 'alt_name:ko_rm': 7, 'name:en_rm': 7, 'heritage:operator': 7, 'sidewalk': 6, 'motorroad': 6, 'name:fr': 6, 'restriction': 6, 'bridge:alt_name:en': 6, 'turn:lanes:backward': 6, 'source:tunnel': 6, 'ncat:tunnel': 6, 'min_height': 6, 'area:highway': 5, 'roof:colour': 5, 'ref:whc': 5, 'whc:criteria': 5, 'FIXME': 5, 'atm': 5, 'whc:inscription_date': 5, 'lanes:forward': 5, 'email': 5, 'lanes:backward': 5, 'cycleway:right': 5, 'addr:city:en': 5, 'location': 5, 'contact:website': 5, 'addr:street:en': 5, 'placement:forward': 4, 'roof:height': 4, 'turn:lanes': 4, 'tower:type': 4, 'addr:street:ko_rm': 4, 'motorcycle': 4, 'old_operator': 4, 'name.source:ko': 4, 'castle_type': 4, 'diplomatic': 4, 'name:es': 4, 'maxheight': 4, 'model': 4, 'name:de': 4, 'manufacturer': 4, 'delivery': 4, 'addr:city:ko_rm': 4, 'relocated': 3, 'guided_tours': 3, 'guided_tours:languages': 3, 'color': 3, 'maxweight': 3, 'construction_date': 3, 'tracktype': 3, 'hgv': 3, 'mapillary': 3, 'whc:name': 3, 'tourist_bus': 3, 'capacity': 3, 'guided_tours:fee': 3, 'substation': 3, 'memorial': 3, 'surveillance': 3, 'aircraft:type': 3, 'note:en': 3, 'short_name': 3, 'place_of_worship': 3, 'tomb': 3, 'museum': 3, 'stars': 3, 'aircraft:military': 3, 'fax': 2, 'ROAD_TYPE': 2, 'driving_side': 2, 'REST_VEH': 2, 'opening_date': 2, 'vehicle': 2, 'name:ko_hanja': 2, 'hight': 2, 'outdoor_seating': 2, 'takeaway': 2, 'attraction': 2, 'name_1': 2, 'cha:ref': 2, 'operator:en': 2, 'noexit': 2, 'park_ride': 2, 'noname': 2, 'wikipedia:ko': 2, 'website:en': 2, 'escalator': 2, 'taxi': 2, 'roof:slope:direction': 2, 'contact:fax': 2, 'ruins': 2, 'REST_W': 2, 'name:ru': 2, 'change:lanes:forward': 2, 'change:lanes:backward': 2, 'drive_through': 2, 'bench': 2, 'direction': 2, 'fence_type': 2, 'addr:country': 2, 'seasonal': 2, 'proposed': 2, 'cycleway:left': 2, 'supervised': 2, 'contact:phone': 2, 'branch': 2, 'ROAD_RANK': 2, 'structure': 2, 'building:height': 1, 'name:alt': 1, 'name:uk': 1, 'layer1': 1, 'ref:shm': 1, 'disused': 1, 'contact:google_plus': 1, u'202\\ub3d9': 1, 'source:bridge': 1, 'hoops': 1, 'audioguide:ref': 1, 'narrow': 1, 'room': 1, 'nat_name': 1, 'theatre:genre': 1, 'inscription': 1, 'handrail:left': 1, 'building:min_level': 1, 'pond': 1, u'201\\ub3d9': 1, 'lay': 1, 'platform_screen_doors': 1, 'contact:instagram': 1, 'contact:facebook': 1, 'smoothness': 1, 'is_in:attraction': 1, 'product': 1, 'mtb:scale:uphill': 1, 'internet_access:fee': 1, 'ncat:bridge': 1, 'distance_and_average_time:ko': 1, 'turn': 1, 'owner': 1, 'handrail:right': 1, 'elevator': 1, 'est_width': 1, 'MAX_SPD': 1, 'building:levels:aboveground': 1, 'bridge:name:ko_rm': 1, 'building:groundslope': 1, 'addr:suburb:ko_rm': 1, 'addr:district': 1, 'spirce': 1, 'theatre': 1, 'addr:subdistrict': 1, 'building:colour': 1, 'building:levels:underground': 1, 'branch:en': 1, 'capacity:long': 1, 'name:kr': 1, 'name:el': 1, 'circuits': 1, 'rooms': 1, 'old_name:ko': 1, 'ramp': 1, 'wall': 1, 'ramp:bicycle': 1, 'maxspeed:conditional': 1, 'building_1': 1, 'toilets:disposal': 1, 'ship:type': 1, 'highway_1': 1, 'max_level': 1, 'intermittent': 1, 'sources': 1, 'name:ch': 1, 'lcn': 1, 'short_name:en': 1, 'highspeed': 1, 'amenity_1': 1, 'alt_name:ja': 1, 'boat:type': 1, 'steps': 1, 'addr:province': 1, 'min_level': 1, 'source:building': 1, 'stand': 1, u'name:e\\u028begbeN': 1, 'website:ko': 1, 'site_type': 1, 'name:ar': 1, 'brand': 1, 'ford': 1, 'old_name': 1, 'opening_hours:source': 1, 'oneway:bicycle': 1, 'aerialway:duration': 1, 'old_name:ja': 1, 'theatre:type': 1, 'official_name': 1, 'source:opening_hours': 1, 'replica': 1, 'cables': 1, 'aerialway': 1, 'nam': 1, 'aerialway:occupancy': 1, 'cha:inscription_date': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "node_key = []\n",
    "way_key = []\n",
    "for element in get_element('central-seoul_south-korea.osm'):\n",
    "    if element.tag == 'node':\n",
    "        for tag in element.iter('tag'):\n",
    "            node_key.append(tag.attrib['k'])\n",
    "    elif element.tag == 'way': \n",
    "        for tag in element.iter('tag'):\n",
    "            way_key.append(tag.attrib['k'])\n",
    "node_count = Counter(node_key)\n",
    "way_count = Counter(way_key)\n",
    "print node_count\n",
    "print way_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaning Data\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Problems encountered in the map  \n",
    "---  \n",
    "    Most of data were valid except attribute 'k' and 'v' of tags in nodes and ways. There were few problems in both key and value sides.\n",
    "    \n",
    "    Key Sides\n",
    "    - Names with more than 1 languages('name','name:en','name':jp etc). They are separated by \":\" which should not be sort as 'kind'.  \n",
    "    - There are keys with more than one ':'.\n",
    "    - Too many kinds of \"k\" most of which are inaccurate or inconsistant.  \n",
    "    - Valuse with problematic characters    \n",
    "\n",
    "    Value Sides\n",
    "    - Even though two kinds of postcodes are being used in Korea, still there were “Incorrect” postcodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Sorting out problematic characters  \n",
    "\n",
    "    I wanted to deal some of the problems before data from osm are imported to SQL. I sorted out problematic characters by defining 'PROBLEMCHARS'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Dealing with names  \n",
    "\n",
    "    I tried to deal keys with string 'name' as exception for assigning kinds. However, if there is a word before name (For example like \"bridge:name\" or \"bridge:name:en\"), I separate them and assigned to 'type'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Assigning 'kind'  \n",
    "\n",
    "     For the rest, I assigned 'kind' and shaped them into CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Dealing with inconsistant 'k' value\n",
    "\n",
    "    I used Counter function to figure out usage of keys. I've discovered there are some outliers with too few usage. I tried to limit the candidate of 'k' with more than 10 elements. \n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: \n",
      "['is_in', 'addr:street', 'level', 'ref', 'level:ref', 'subway', 'bicycle', 'access', 'source:bridge', 'camera:direction', 'amenity', 'alt_name', 'fee', 'start_date', 'entrance', 'phone', 'species', 'information', 'name:fr', 'description', 'natural', 'wheelchair', 'office', 'old_operator', 'addr:housenumber', 'camera:mount', 'covered', 'image', 'junction', 'material', 'camera:type', 'foot', 'tourism', 'payment:bitcoin', 'fixme', 'name', 'designation', 'crossing', 'network', 'name:zh', 'highway', 'barrier', 'ncat:bridge', 'noexit', 'atm', 'place', 'addr:housename', 'station', 'building', 'bridge:name:ko', 'aeroway', 'landuse', 'bridge', 'bridge:name:ko_rm', 'sport', 'note', 'tank:type', 'shop', 'name:ko', 'indoor', 'leisure', 'name:el', 'name:en', 'addr:postcode', 'internet_access:fee', 'public_transport', 'leaf_cycle', 'cannon:type', 'historic:period', 'bridge:name:en', 'route_ref', 'parking', 'capacity', 'historic:civilization', 'wikipedia', 'mapillary', 'ele', 'denomination', 'board_type', 'alt_name:ko', 'railway', 'ncat', 'height', 'bench', 'description:en', 'surveillance:zone', 'building:material', 'website', 'direction', 'smoking', 'bridge:name', 'layer', 'backrest', 'cuisine', 'memorial', 'surveillance', 'statue', 'genus', 'colour', 'aircraft:type', 'model', 'seats', 'name:de', 'source', 'surveillance:type', 'emergency', 'historic', 'addr:city', 'internet_access', 'platforms', 'man_made', 'religion', 'artwork_type', 'name:ja', 'power', 'takeaway', 'name:ko_rm', 'manufacturer', 'taxon', 'contact:website', 'operator', 'opening_hours', 'bus', 'brand', 'delivery', 'aircraft:military', 'leaf_type', 'denotation', 'statue:animal', 'route_ref_2', 'route_ref_1']\n",
      "Way: \n",
      "['motor_vehicle', 'addr:street', 'level', 'ref', 'level:ref', 'bicycle', 'access', 'military', 'amenity', 'alt_name', 'fee', 'start_date', 'phone', 'natural', 'wheelchair', 'office', 'addr:housenumber', 'covered', 'image', 'junction', 'material', 'foot', 'tourism', 'fixme', 'name', 'crossing', 'network', 'name:zh', 'highway', 'barrier', 'route', 'access:note', 'horse', 'addr:housename', 'building', 'bridge:name:ko', 'aeroway', 'landuse', 'bridge', 'wikidata', 'sport', 'building:levels', 'note', 'shop', 'name:ko', 'indoor', 'leisure', 'name:en', 'addr:postcode', 'int_name', 'historic:period', 'bridge:name:en', 'parking', 'historic:civilization', 'wikipedia', 'ele', 'denomination', 'alt_name:ko', 'railway', 'ncat', 'height', 'description:en', 'building:material', 'website', 'smoking', 'bridge:name', 'layer', 'alt_name:en', 'surface', 'waterway', 'cuisine', 'colour', 'source', 'emergency', 'historic', 'addr:city', 'internet_access', 'man_made', 'religion', 'name:ja', 'name:ko_rm', 'operator', 'opening_hours', 'heritage', 'admin_level', 'bus']\n"
     ]
    }
   ],
   "source": [
    "freq_node = [key for key in node_count if node_count[key] >10] \n",
    "freq_way = [key for key in node_count if way_count[key] >10] \n",
    "print \"Node: \"\n",
    "print freq_node\n",
    "print \"Way: \"\n",
    "print freq_way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    # Deal with node;\n",
    "    if element.tag == 'node':\n",
    "        for i in node_attr_fields:\n",
    "            node_attribs[i] = element.attrib[i]\n",
    "    # Deal with node - tag;\n",
    "        tags = []  \n",
    "        for tag in element.iter('tag'):\n",
    "        # Sort out problematic characters / Limit the 'v' candidates\n",
    "            if (problem_chars.search(tag.attrib['k'])) or (tag.attrib['v'] not in freq_node):\n",
    "                pass\n",
    "            else:\n",
    "                tagdic = {}\n",
    "                tagdic['id'] = element.attrib['id']\n",
    "                if \":\" in tag.attrib['k']:\n",
    "        # Keep the name\n",
    "                    if \"name\" in tag.attrib['k']:\n",
    "                        if \":name\" in tag.attrib['k']:\n",
    "        # Assign types\n",
    "                            k = list(tag.attrib['k'].split(\":\"))\n",
    "                            if len(k) == 2:\n",
    "                                tagdic['key'] = k[1]\n",
    "                                tagdic['type'] = k[0]\n",
    "                                tagdic['value'] = tag.attrib['v']\n",
    "                                tags.append(tagdic)\n",
    "                            else:\n",
    "                                tagdic['key'] = k[1]+\":\"+k[2]\n",
    "                                tagdic['type'] = k[0]\n",
    "                                tagdic['value'] = tag.attrib['v']\n",
    "                                tags.append(tagdic)                                \n",
    "                        else:\n",
    "                            tagdic['key'] = tag.attrib['k']\n",
    "                            tagdic['type'] = 'regular'\n",
    "                            tagdic['value'] = tag.attrib['v']\n",
    "                            tags.append(tagdic)\n",
    "                    else: \n",
    "                        k = list(tag.attrib['k'].split(\":\"))\n",
    "                        if len(k) == 2:\n",
    "                            tagdic['key'] = k[1]\n",
    "                            tagdic['type'] = k[0]\n",
    "                            tagdic['value'] = tag.attrib['v']\n",
    "                            tags.append(tagdic)\n",
    "                        else:\n",
    "                            tagdic['key'] = k[1]+\":\"+k[2]\n",
    "                            tagdic['type'] = k[0]\n",
    "                            tagdic['value'] = tag.attrib['v']\n",
    "                            tags.append(tagdic)\n",
    "                else:\n",
    "                    tagdic['key'] = tag.attrib['k']\n",
    "                    tagdic['type'] = 'regular'\n",
    "                    tagdic['value'] = tag.attrib['v']\n",
    "                    tags.append(tagdic)\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    # Deal with way;\n",
    "    elif element.tag == 'way':\n",
    "        for i in way_attr_fields:\n",
    "            way_attribs[i] = element.attrib[i]\n",
    "    # Deal with way - nd;\n",
    "        count = 0\n",
    "        for node in element.iter(\"nd\"):\n",
    "            nd = {}\n",
    "            nd['id'] = element.attrib['id']\n",
    "            nd['node_id'] = node.attrib['ref']\n",
    "            nd['position'] = count\n",
    "            way_nodes.append(nd)\n",
    "            count += 1\n",
    "    # Deal with way - tag;\n",
    "        tags = []  \n",
    "        for tag in element.iter('tag'):\n",
    "        # Sort out problematic characters / Limit the 'v' candidates\n",
    "            if (problem_chars.search(tag.attrib['k'])) or (tag.attrib['v'] not in freq_way):\n",
    "                pass\n",
    "            else:\n",
    "                tagdic = {}\n",
    "                tagdic['id'] = element.attrib['id']\n",
    "                if \":\" in tag.attrib['k']:\n",
    "        # Keep the name\n",
    "                    if \"name\" in tag.attrib['k']:\n",
    "                        if \":name\" in tag.attrib['k']:\n",
    "        # Assign types\n",
    "                            k = list(tag.attrib['k'].split(\":\"))\n",
    "                            if len(k) == 2:\n",
    "                                tagdic['key'] = k[1]\n",
    "                                tagdic['type'] = k[0]\n",
    "                                tagdic['value'] = tag.attrib['v']\n",
    "                                tags.append(tagdic)\n",
    "                            else:\n",
    "                                tagdic['key'] = k[1]+\":\"+k[2]\n",
    "                                tagdic['type'] = k[0]\n",
    "                                tagdic['value'] = tag.attrib['v']\n",
    "                                tags.append(tagdic)                                \n",
    "                        else:\n",
    "                            tagdic['key'] = tag.attrib['k']\n",
    "                            tagdic['type'] = 'regular'\n",
    "                            tagdic['value'] = tag.attrib['v']\n",
    "                            tags.append(tagdic)\n",
    "                    else: \n",
    "                        k = list(tag.attrib['k'].split(\":\"))\n",
    "                        if len(k) == 2:\n",
    "                            tagdic['key'] = k[1]\n",
    "                            tagdic['type'] = k[0]\n",
    "                            tagdic['value'] = tag.attrib['v']\n",
    "                            tags.append(tagdic)\n",
    "                        else:\n",
    "                            tagdic['key'] = k[1]+\":\"+k[2]\n",
    "                            tagdic['type'] = k[0]\n",
    "                            tagdic['value'] = tag.attrib['v']\n",
    "                            tags.append(tagdic)\n",
    "                else:\n",
    "                    tagdic['key'] = tag.attrib['k']\n",
    "                    tagdic['type'] = 'regular'\n",
    "                    tagdic['value'] = tag.attrib['v']\n",
    "                    tags.append(tagdic)\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Write on CSV file\n",
    "    File named \n",
    "        nodes.csv,\n",
    "        nodes_tags.csv,\n",
    "        ways.csv,\n",
    "        ways_nodes.csv,\n",
    "        ways_tags.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "        count = 0\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            if count%1 == 0:\n",
    "                el = shape_element(element)\n",
    "                if el:\n",
    "                    if validate is True:\n",
    "                        validate_element(el, validator)\n",
    "\n",
    "                    if element.tag == 'node':\n",
    "                        nodes_writer.writerow(el['node'])\n",
    "                        node_tags_writer.writerows(el['node_tags'])\n",
    "                    elif element.tag == 'way':\n",
    "                        ways_writer.writerow(el['way'])\n",
    "                        way_nodes_writer.writerows(el['way_nodes'])\n",
    "                        way_tags_writer.writerows(el['way_tags'])\n",
    "            count += 1\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Updating wrong postcodes\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Import to SQL\n",
    "    1.\n",
    "    sqlite3 osm.db\n",
    "    2.\n",
    "    CREATE TABLE nodes (\n",
    "        id INTEGER PRIMARY KEY NOT NULL,\n",
    "        lat REAL,\n",
    "        lon REAL,\n",
    "        user TEXT,\n",
    "        uid INTEGER,\n",
    "        version INTEGER,\n",
    "        changeset INTEGER,\n",
    "        timestamp TEXT\n",
    "    );\n",
    "\n",
    "    CREATE TABLE nodes_tags (\n",
    "        id INTEGER,\n",
    "        key TEXT,\n",
    "        value TEXT,\n",
    "        type TEXT,\n",
    "        FOREIGN KEY (id) REFERENCES nodes(id)\n",
    "    );\n",
    "\n",
    "    CREATE TABLE ways (\n",
    "        id INTEGER PRIMARY KEY NOT NULL,\n",
    "        user TEXT,\n",
    "        uid INTEGER,\n",
    "        version TEXT,\n",
    "        changeset INTEGER,\n",
    "        timestamp TEXT\n",
    "    );\n",
    "\n",
    "    CREATE TABLE ways_tags (\n",
    "        id INTEGER NOT NULL,\n",
    "        key TEXT NOT NULL,\n",
    "        value TEXT NOT NULL,\n",
    "        type TEXT,\n",
    "        FOREIGN KEY (id) REFERENCES ways(id)\n",
    "    );\n",
    "\n",
    "    CREATE TABLE ways_nodes (\n",
    "        id INTEGER NOT NULL,\n",
    "        node_id INTEGER NOT NULL,\n",
    "        position INTEGER NOT NULL,\n",
    "        FOREIGN KEY (id) REFERENCES ways(id),\n",
    "        FOREIGN KEY (node_id) REFERENCES nodes(id)\n",
    "    );\n",
    "    3.\n",
    "    .import desktop/project/nodes.csv nodes\n",
    "    .import desktop/project/nodes_tags.csv nodes_tags\n",
    "    .import desktop/project/ways.csv ways\n",
    "    .import desktop/project/ways_tags.csv ways_tags\n",
    "    .import desktop/project/ways_nodes.csv ways_nodes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "db = sqlite3.connect(\"osm.db\")\n",
    "c = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0       1  2\n",
      "0  1784228299  137070  6\n",
      "1  1918198776  135070  6\n",
      "2  2099140167     135  3\n",
      "3  4132075644  107-36  6\n"
     ]
    }
   ],
   "source": [
    "QUERY = \"\"\"\n",
    "SELECT id, value, LENGTH(value) as total\n",
    "FROM nodes_tags \n",
    "WHERE key ='postcode' and \n",
    "total != 7 and\n",
    "total != 5;\n",
    "\"\"\"\n",
    "c.execute(QUERY)\n",
    "rows = c.fetchall()\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0       1  2\n",
      "0  152764379  121839  6\n",
      "1  323234688  122749  6\n",
      "2  323234965  122749  6\n",
      "3  323242342  122749  6\n",
      "4  323243332  122749  6\n",
      "5  420009951  122807  6\n"
     ]
    }
   ],
   "source": [
    "QUERY = \"\"\"\n",
    "SELECT id, value, LENGTH(value) as total\n",
    "FROM ways_tags \n",
    "WHERE key ='postcode' and \n",
    "total != 7 and\n",
    "total != 5;\n",
    "\"\"\"\n",
    "c.execute(QUERY)\n",
    "rows = c.fetchall()\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Among 10 flawed postcode, I decied to correct 8 of them with missing '-' and drop 2 of them. Used 'update' and 'delete' to clean the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "QUERY = \"\"\"\n",
    "UPDATE nodes_tags\n",
    "SET value = '137-070'\n",
    "WHERE id = 1784228299;\n",
    "\"\"\"\n",
    "c.execute(QUERY)\n",
    "\n",
    "QUERY = \"\"\"\n",
    "UPDATE nodes_tags\n",
    "SET value = '135-070'\n",
    "WHERE id = 1918198776;\n",
    "\"\"\"\n",
    "c.execute(QUERY)\n",
    "\n",
    "QUERY = \"\"\"\n",
    "UPDATE ways_tags\n",
    "SET value = '121-839'\n",
    "WHERE id = 152764379;\n",
    "\"\"\"\n",
    "c.execute(QUERY)\n",
    "\n",
    "QUERY = \"\"\"\n",
    "UPDATE ways_tags\n",
    "SET value = '122-749'\n",
    "WHERE id = 323234688 or\n",
    "id = 323234965 or\n",
    "id = 323242342 or\n",
    "id = 323243332;\n",
    "\"\"\"\n",
    "c.execute(QUERY)\n",
    "\n",
    "QUERY = \"\"\"\n",
    "UPDATE ways_tags\n",
    "SET value = '122-807'\n",
    "WHERE id = 420009951;\n",
    "\"\"\"\n",
    "c.execute(QUERY)\n",
    "\n",
    "QUERY = \"\"\"\n",
    "DELETE FROM nodes_tags\n",
    "WHERE id = 2099140167 or\n",
    "id = 4132075644;\n",
    "\"\"\"\n",
    "c.execute(QUERY)\n",
    "\n",
    "QUERY = \"\"\"\n",
    "SELECT id, value, LENGTH(value) as total\n",
    "FROM nodes_tags \n",
    "WHERE key ='postcode' and \n",
    "total != 7 and\n",
    "total != 5;\n",
    "\"\"\"\n",
    "c.execute(QUERY)\n",
    "rows = c.fetchall()\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(rows)\n",
    "print df\n",
    "\n",
    "QUERY = \"\"\"\n",
    "SELECT id, value, LENGTH(value) as total\n",
    "FROM ways_tags \n",
    "WHERE key ='postcode' and \n",
    "total != 7 and\n",
    "total != 5;\n",
    "\"\"\"\n",
    "c.execute(QUERY)\n",
    "rows = c.fetchall()\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Overview and Additional Ideas\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) File sizes\n",
    "---\n",
    "    central-seoul_south-korea.osm .. 79.5 MB\n",
    "    osm.db ......................... 44.2 MB\n",
    "    nodes.csv ...................... 27.8 MB\n",
    "    nodes_tags.csv ................. 61 KB\n",
    "    ways.csv ....................... 3.6 MB\n",
    "    ways_tags.csv .................. 27 KB\n",
    "    ways_nodes.cv .................. 10.1 MB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Number of nodes\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333753\n"
     ]
    }
   ],
   "source": [
    "QUERY = \"\"\"\n",
    "SELECT COUNT(*) FROM nodes;\n",
    "\"\"\"\n",
    "c.execute(QUERY)\n",
    "rows = c.fetchall()\n",
    "print rows[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Number of ways\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60047\n"
     ]
    }
   ],
   "source": [
    "QUERY = \"\"\"\n",
    "SELECT COUNT(*) FROM ways;\n",
    "\"\"\"\n",
    "c.execute(QUERY)\n",
    "rows = c.fetchall()\n",
    "print rows[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Number of unique users\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "982\n"
     ]
    }
   ],
   "source": [
    "QUERY = \"\"\"\n",
    "SELECT COUNT(DISTINCT(e.uid))          \n",
    "FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e;\n",
    "\"\"\"\n",
    "c.execute(QUERY)\n",
    "rows = c.fetchall()\n",
    "print rows[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Top 10 contributing users\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0      1\n",
      "0   maphunter36  47588\n",
      "1      panhoong  35381\n",
      "2       GPIOIPG  27520\n",
      "3        dabeeo  26366\n",
      "4          Exj　  22700\n",
      "5  CitymapperHQ  19030\n",
      "6          thbz  14088\n",
      "7     bizarre07  13634\n",
      "8       dabeeo2   9857\n",
      "9     Stleamist   9282\n"
     ]
    }
   ],
   "source": [
    "QUERY = \"\"\"\n",
    "SELECT e.user, COUNT(*) as num\n",
    "FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e\n",
    "GROUP BY e.user\n",
    "ORDER BY num DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "c.execute(QUERY)\n",
    "rows = c.fetchall()\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Number of users appearing only once (having 1 post)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312\n"
     ]
    }
   ],
   "source": [
    "QUERY = \"\"\"\n",
    "SELECT COUNT(*) \n",
    "FROM\n",
    "(SELECT e.user, COUNT(*) as num\n",
    " FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e\n",
    " GROUP BY e.user\n",
    " HAVING num=1)  u;\n",
    "\"\"\"\n",
    "c.execute(QUERY)\n",
    "rows = c.fetchall()\n",
    "print rows[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ideas\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Numbers of universities in Seoul\n",
    "\n",
    "    . Since I am a university student, I wanted to find out how many universities in Seoul. First, I tried to find university in 'name' key, but I soon realized it would be impossible to find name that ends with the word '대학교(which means university)' or they contain numerous kinds of primary schools, hospitals, museum etc. So I tried to query with the key 'name:ko' and 'name'en'. A bit surprising that there were approximately 55/59(Korean/English) universities in Seoul. Quite a lot! I could find my '고려대학교'(Korea University), but I couldn't find '연세대학교'(Yonsei University)...(Sorry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0   1\n",
      "0  name:ko  55\n"
     ]
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT key, count(key)\n",
    "FROM nodes_tags\n",
    "WHERE key = 'name:ko' and\n",
    "value LIKE '%대학교' and\n",
    "value != '대학교';\n",
    "'''\n",
    "#To find the list, change count(key) to value.\n",
    "c.execute(QUERY)\n",
    "rows = c.fetchall()\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0                                1\n",
      "0  name:en      Korea Pollitek 1 University\n",
      "1  name:en      Korea Pollitek 1 University\n",
      "2  name:en            Korea Open University\n",
      "3  name:en           Korea Cyber University\n",
      "4  name:en                 Korea University\n",
      "5  name:en            Korea Open University\n",
      "6  name:en            Korea Open University\n",
      "7  name:en  Korea Bencheojeongbo University\n"
     ]
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT key, value\n",
    "FROM nodes_tags\n",
    "WHERE key = 'name:en' and\n",
    "value LIKE '%korea%' and\n",
    "value LIKE '%university' and\n",
    "value != 'university';\n",
    "'''\n",
    "c.execute(QUERY)\n",
    "rows = c.fetchall()\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT key, value\n",
    "FROM nodes_tags\n",
    "WHERE key = 'name:en' and\n",
    "value LIKE '%yonsei%' and\n",
    "value LIKE '%university' and\n",
    "value != 'university';\n",
    "'''\n",
    "c.execute(QUERY)\n",
    "rows = c.fetchall()\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Top 10 Most Popular Amenities\n",
    "---\n",
    "    This list reflects the culture of eating out in Seoul...(Too many reastaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0    1\n",
      "0   restaurant  687\n",
      "1         bank  674\n",
      "2       school  514\n",
      "3         cafe  415\n",
      "4         fuel  323\n",
      "5       police  286\n",
      "6     townhall  279\n",
      "7      library  260\n",
      "8  post_office  245\n",
      "9     hospital  237\n"
     ]
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT value, COUNT(*) as num\n",
    "FROM nodes_tags\n",
    "WHERE key='amenity'\n",
    "GROUP BY value\n",
    "ORDER BY num DESC\n",
    "LIMIT 10;\n",
    "'''\n",
    "c.execute(QUERY)\n",
    "rows = c.fetchall()\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(rows)\n",
    "print df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Top 10 Popular Foods   \n",
    "\n",
    "    Korean was the most popular food in Seoul(Of Course...)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0   1\n",
      "0       korean  40\n",
      "1     regional  22\n",
      "2      chinese  15\n",
      "3      italian  15\n",
      "4     japanese  15\n",
      "5        pizza  14\n",
      "6        asian   9\n",
      "7  coffee_shop   5\n",
      "8      mexican   5\n",
      "9     american   4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "QUERY = '''\n",
    "SELECT nodes_tags.value, COUNT(*) as num\n",
    "FROM nodes_tags \n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='restaurant') i\n",
    "    ON nodes_tags.id=i.id\n",
    "WHERE nodes_tags.key='cuisine'\n",
    "GROUP BY nodes_tags.value\n",
    "ORDER BY num DESC\n",
    "limit 10;\n",
    "'''\n",
    "c.execute(QUERY)\n",
    "rows = c.fetchall()\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Top 10 banks in Seoul\n",
    "---\n",
    "    Among the titled, '우리은행' has the most nodes. I thought there were too few banks named '농협', but I figured out the way they named was not just '농협' but like '관악농협신림지점앞' which state the place of bank with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0   1\n",
      "0         우리은행  88\n",
      "1         신한은행  70\n",
      "2         하나은행  65\n",
      "3         국민은행  61\n",
      "4         기업은행  32\n",
      "5         외환은행  32\n",
      "6           농협  31\n",
      "7  한국스탠다드차타드은행  20\n",
      "8         씨티은행  14\n",
      "9        새마을금고  12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "QUERY = '''\n",
    "SELECT nodes_tags.value, COUNT(*) as num\n",
    "FROM nodes_tags \n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='bank') i\n",
    "    ON nodes_tags.id=i.id\n",
    "where key = 'name' or\n",
    "key = 'name:ko' or\n",
    "key = 'name:en'\n",
    "GROUP BY nodes_tags.value\n",
    "ORDER BY num DESC\n",
    "limit 10;\n",
    "'''\n",
    "c.execute(QUERY)\n",
    "rows = c.fetchall()\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Top 10 coffeeshop in Seoul\n",
    "---\n",
    "    I think the number of coffeshop is way too small for Seoul. I guess Most of them are untitled. Top 1, 2, 4, 5were all Starbucks in different names(스타벅스 is Starbucks in Korean). I think these can be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0   1\n",
      "0         Starbucks  24\n",
      "1              스타벅스   8\n",
      "2      Ediya Coffee   7\n",
      "3         STARBUCKS   7\n",
      "4  Starbucks Coffee   7\n",
      "5              카페베네   6\n",
      "6               커피빈   6\n",
      "7    Dunkin' Donuts   5\n",
      "8    Holly's Coffee   5\n",
      "9          Pascucci   5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "QUERY = '''\n",
    "SELECT nodes_tags.value, COUNT(*) as num\n",
    "FROM nodes_tags \n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='cafe') i\n",
    "    ON nodes_tags.id=i.id\n",
    "where key = 'name' or\n",
    "key = 'name:ko' or\n",
    "key = 'name:en'\n",
    "GROUP BY nodes_tags.value\n",
    "ORDER BY num DESC\n",
    "limit 10;\n",
    "'''\n",
    "c.execute(QUERY)\n",
    "rows = c.fetchall()\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(rows)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "    The data of Seoul was quite well organized than expected though there are some incompleteness. Especially, the fact that most of the values were provided in Korean was quite impressive considering the popularity of OSM in Korea. Yet, there are much more things could be done. \n",
    "    1. Solution: Some errors found here(Some errors in postcodes, inconsistant name of Starbucks) could be fixed. \n",
    "        - Benifit\n",
    "            1) Consistant names would contribute to more precise statictics.\n",
    "            2) Precise postcodes can be use for functional purpose.\n",
    "        - Anticipated Problems\n",
    "            1) All the check should be done by human - would take lots of time and effort.\n",
    "            2) It would be hard to check the absent postcodes.\n",
    "    2. Solution: Nodes should have complete tags of 'name', 'name:ko' and 'name:en'(At least in two languages). \n",
    "        - Benifit\n",
    "            1) Statistics would show consistant result, not varies by languages.\n",
    "            2) Foreigners would not be confused to see mixed up names\n",
    "        - Anticipated Problems\n",
    "            1) All the check should be done by human - would take lots of time and effort.\n",
    "            2) It would be hard to check the absent names.\n",
    "    3. Solution: Mixed up between the nodes and ways could be fixed. \n",
    "        - Benifit\n",
    "            1) Classification between nodes and ways would be more accurate.\n",
    "        - Anticipated Problems\n",
    "            1) There are too much nodes informations on ways(would take some time to fix all).\n",
    "            2) There are some obscure nodes which can be seen as both nodes or ways.\n",
    "    I think the GPS and node data in OSM are really valueable, so it would be crucial to clean and improve data in order to make useful use of this dataset."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
